{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc5f9618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as ag_np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "DATA_DIR = './data_movie_lens_100k'\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5527e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = load_train_valid_test_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e9e1362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:0.86929\teval-mae:0.86908\n",
      "[1]\ttrain-mae:0.85482\teval-mae:0.85781\n",
      "[2]\ttrain-mae:0.83460\teval-mae:0.84126\n",
      "[3]\ttrain-mae:0.82326\teval-mae:0.83173\n",
      "[4]\ttrain-mae:0.81291\teval-mae:0.82345\n",
      "[5]\ttrain-mae:0.79748\teval-mae:0.81050\n",
      "[6]\ttrain-mae:0.78420\teval-mae:0.79944\n",
      "[7]\ttrain-mae:0.77519\teval-mae:0.79260\n",
      "[8]\ttrain-mae:0.76548\teval-mae:0.78471\n",
      "[9]\ttrain-mae:0.76020\teval-mae:0.78053\n",
      "[10]\ttrain-mae:0.75549\teval-mae:0.77688\n",
      "[11]\ttrain-mae:0.74873\teval-mae:0.77188\n",
      "[12]\ttrain-mae:0.74528\teval-mae:0.76928\n",
      "[13]\ttrain-mae:0.74211\teval-mae:0.76690\n",
      "[14]\ttrain-mae:0.73808\teval-mae:0.76391\n",
      "[15]\ttrain-mae:0.73311\teval-mae:0.76024\n",
      "[16]\ttrain-mae:0.72889\teval-mae:0.75706\n",
      "[17]\ttrain-mae:0.72504\teval-mae:0.75412\n",
      "[18]\ttrain-mae:0.72269\teval-mae:0.75251\n",
      "[19]\ttrain-mae:0.72060\teval-mae:0.75116\n",
      "[20]\ttrain-mae:0.71920\teval-mae:0.75022\n",
      "[21]\ttrain-mae:0.71797\teval-mae:0.74943\n",
      "[22]\ttrain-mae:0.71554\teval-mae:0.74759\n",
      "[23]\ttrain-mae:0.71344\teval-mae:0.74597\n",
      "[24]\ttrain-mae:0.71145\teval-mae:0.74457\n",
      "[25]\ttrain-mae:0.71031\teval-mae:0.74401\n",
      "[26]\ttrain-mae:0.70896\teval-mae:0.74297\n",
      "[27]\ttrain-mae:0.70839\teval-mae:0.74272\n",
      "[28]\ttrain-mae:0.70710\teval-mae:0.74193\n",
      "[29]\ttrain-mae:0.70601\teval-mae:0.74123\n",
      "[30]\ttrain-mae:0.70537\teval-mae:0.74096\n",
      "[31]\ttrain-mae:0.70450\teval-mae:0.74038\n",
      "[32]\ttrain-mae:0.70419\teval-mae:0.74024\n",
      "[33]\ttrain-mae:0.70343\teval-mae:0.73979\n",
      "[34]\ttrain-mae:0.70317\teval-mae:0.73970\n",
      "[35]\ttrain-mae:0.70297\teval-mae:0.73963\n",
      "[36]\ttrain-mae:0.70253\teval-mae:0.73940\n",
      "[37]\ttrain-mae:0.70208\teval-mae:0.73927\n",
      "[38]\ttrain-mae:0.70175\teval-mae:0.73909\n",
      "[39]\ttrain-mae:0.70106\teval-mae:0.73868\n",
      "[40]\ttrain-mae:0.70088\teval-mae:0.73860\n",
      "[41]\ttrain-mae:0.70015\teval-mae:0.73808\n",
      "[42]\ttrain-mae:0.69958\teval-mae:0.73786\n",
      "[43]\ttrain-mae:0.69905\teval-mae:0.73747\n",
      "[44]\ttrain-mae:0.69879\teval-mae:0.73741\n",
      "[45]\ttrain-mae:0.69844\teval-mae:0.73729\n",
      "[46]\ttrain-mae:0.69827\teval-mae:0.73715\n",
      "[47]\ttrain-mae:0.69816\teval-mae:0.73713\n",
      "[48]\ttrain-mae:0.69805\teval-mae:0.73707\n",
      "[49]\ttrain-mae:0.69790\teval-mae:0.73710\n",
      "[50]\ttrain-mae:0.69774\teval-mae:0.73710\n",
      "[51]\ttrain-mae:0.69709\teval-mae:0.73679\n",
      "[52]\ttrain-mae:0.69685\teval-mae:0.73675\n",
      "[53]\ttrain-mae:0.69638\teval-mae:0.73645\n",
      "[54]\ttrain-mae:0.69616\teval-mae:0.73647\n",
      "[55]\ttrain-mae:0.69566\teval-mae:0.73613\n",
      "[56]\ttrain-mae:0.69544\teval-mae:0.73602\n",
      "[57]\ttrain-mae:0.69512\teval-mae:0.73588\n",
      "[58]\ttrain-mae:0.69502\teval-mae:0.73584\n",
      "[59]\ttrain-mae:0.69473\teval-mae:0.73568\n",
      "[60]\ttrain-mae:0.69459\teval-mae:0.73560\n",
      "[61]\ttrain-mae:0.69430\teval-mae:0.73542\n",
      "[62]\ttrain-mae:0.69416\teval-mae:0.73538\n",
      "[63]\ttrain-mae:0.69398\teval-mae:0.73532\n",
      "[64]\ttrain-mae:0.69387\teval-mae:0.73535\n",
      "[65]\ttrain-mae:0.69352\teval-mae:0.73523\n",
      "[66]\ttrain-mae:0.69333\teval-mae:0.73514\n",
      "[67]\ttrain-mae:0.69321\teval-mae:0.73515\n",
      "[68]\ttrain-mae:0.69283\teval-mae:0.73496\n",
      "[69]\ttrain-mae:0.69272\teval-mae:0.73500\n",
      "[70]\ttrain-mae:0.69262\teval-mae:0.73498\n",
      "[71]\ttrain-mae:0.69253\teval-mae:0.73498\n",
      "[72]\ttrain-mae:0.69219\teval-mae:0.73469\n",
      "[73]\ttrain-mae:0.69208\teval-mae:0.73472\n",
      "[74]\ttrain-mae:0.69182\teval-mae:0.73472\n",
      "[75]\ttrain-mae:0.69172\teval-mae:0.73478\n",
      "[76]\ttrain-mae:0.69153\teval-mae:0.73475\n",
      "[77]\ttrain-mae:0.69141\teval-mae:0.73466\n",
      "[78]\ttrain-mae:0.69128\teval-mae:0.73460\n",
      "[79]\ttrain-mae:0.69093\teval-mae:0.73444\n",
      "[80]\ttrain-mae:0.69076\teval-mae:0.73432\n",
      "[81]\ttrain-mae:0.69067\teval-mae:0.73438\n",
      "[82]\ttrain-mae:0.69054\teval-mae:0.73438\n",
      "[83]\ttrain-mae:0.69041\teval-mae:0.73436\n",
      "[84]\ttrain-mae:0.69031\teval-mae:0.73432\n",
      "[85]\ttrain-mae:0.69018\teval-mae:0.73436\n",
      "[86]\ttrain-mae:0.69005\teval-mae:0.73440\n",
      "[87]\ttrain-mae:0.68998\teval-mae:0.73439\n",
      "[88]\ttrain-mae:0.68982\teval-mae:0.73430\n",
      "[89]\ttrain-mae:0.68967\teval-mae:0.73430\n",
      "[90]\ttrain-mae:0.68960\teval-mae:0.73433\n",
      "[91]\ttrain-mae:0.68948\teval-mae:0.73429\n",
      "[92]\ttrain-mae:0.68940\teval-mae:0.73428\n",
      "[93]\ttrain-mae:0.68911\teval-mae:0.73422\n",
      "[94]\ttrain-mae:0.68898\teval-mae:0.73420\n",
      "[95]\ttrain-mae:0.68887\teval-mae:0.73412\n",
      "[96]\ttrain-mae:0.68866\teval-mae:0.73413\n",
      "[97]\ttrain-mae:0.68852\teval-mae:0.73410\n",
      "[98]\ttrain-mae:0.68837\teval-mae:0.73405\n",
      "[99]\ttrain-mae:0.68821\teval-mae:0.73405\n",
      "[100]\ttrain-mae:0.68801\teval-mae:0.73409\n",
      "[101]\ttrain-mae:0.68796\teval-mae:0.73410\n",
      "[102]\ttrain-mae:0.68788\teval-mae:0.73410\n",
      "[103]\ttrain-mae:0.68779\teval-mae:0.73409\n",
      "[104]\ttrain-mae:0.68768\teval-mae:0.73405\n",
      "[105]\ttrain-mae:0.68760\teval-mae:0.73403\n",
      "[106]\ttrain-mae:0.68752\teval-mae:0.73404\n",
      "[107]\ttrain-mae:0.68732\teval-mae:0.73393\n",
      "[108]\ttrain-mae:0.68724\teval-mae:0.73392\n",
      "[109]\ttrain-mae:0.68716\teval-mae:0.73386\n",
      "[110]\ttrain-mae:0.68709\teval-mae:0.73380\n",
      "[111]\ttrain-mae:0.68703\teval-mae:0.73376\n",
      "[112]\ttrain-mae:0.68695\teval-mae:0.73371\n",
      "[113]\ttrain-mae:0.68685\teval-mae:0.73367\n",
      "[114]\ttrain-mae:0.68680\teval-mae:0.73363\n",
      "[115]\ttrain-mae:0.68664\teval-mae:0.73363\n",
      "[116]\ttrain-mae:0.68651\teval-mae:0.73356\n",
      "[117]\ttrain-mae:0.68635\teval-mae:0.73362\n",
      "[118]\ttrain-mae:0.68633\teval-mae:0.73363\n",
      "[119]\ttrain-mae:0.68627\teval-mae:0.73364\n",
      "[120]\ttrain-mae:0.68611\teval-mae:0.73361\n",
      "[121]\ttrain-mae:0.68600\teval-mae:0.73359\n",
      "[122]\ttrain-mae:0.68595\teval-mae:0.73357\n",
      "[123]\ttrain-mae:0.68589\teval-mae:0.73361\n",
      "[124]\ttrain-mae:0.68581\teval-mae:0.73362\n",
      "[125]\ttrain-mae:0.68577\teval-mae:0.73362\n",
      "[126]\ttrain-mae:0.68573\teval-mae:0.73360\n",
      "[127]\ttrain-mae:0.68568\teval-mae:0.73356\n",
      "[128]\ttrain-mae:0.68560\teval-mae:0.73356\n",
      "[129]\ttrain-mae:0.68554\teval-mae:0.73359\n",
      "[130]\ttrain-mae:0.68549\teval-mae:0.73354\n",
      "[131]\ttrain-mae:0.68545\teval-mae:0.73354\n",
      "[132]\ttrain-mae:0.68521\teval-mae:0.73352\n",
      "[133]\ttrain-mae:0.68517\teval-mae:0.73352\n",
      "[134]\ttrain-mae:0.68511\teval-mae:0.73350\n",
      "[135]\ttrain-mae:0.68492\teval-mae:0.73335\n",
      "[136]\ttrain-mae:0.68483\teval-mae:0.73334\n",
      "[137]\ttrain-mae:0.68478\teval-mae:0.73333\n",
      "[138]\ttrain-mae:0.68471\teval-mae:0.73335\n",
      "[139]\ttrain-mae:0.68463\teval-mae:0.73335\n",
      "[140]\ttrain-mae:0.68457\teval-mae:0.73339\n",
      "[141]\ttrain-mae:0.68446\teval-mae:0.73338\n",
      "[142]\ttrain-mae:0.68441\teval-mae:0.73339\n",
      "[143]\ttrain-mae:0.68435\teval-mae:0.73336\n",
      "[144]\ttrain-mae:0.68423\teval-mae:0.73332\n",
      "[145]\ttrain-mae:0.68415\teval-mae:0.73325\n",
      "[146]\ttrain-mae:0.68406\teval-mae:0.73320\n",
      "[147]\ttrain-mae:0.68402\teval-mae:0.73320\n",
      "[148]\ttrain-mae:0.68396\teval-mae:0.73313\n",
      "[149]\ttrain-mae:0.68390\teval-mae:0.73311\n",
      "[150]\ttrain-mae:0.68373\teval-mae:0.73315\n",
      "[151]\ttrain-mae:0.68367\teval-mae:0.73310\n",
      "[152]\ttrain-mae:0.68351\teval-mae:0.73295\n",
      "[153]\ttrain-mae:0.68345\teval-mae:0.73293\n",
      "[154]\ttrain-mae:0.68340\teval-mae:0.73287\n",
      "[155]\ttrain-mae:0.68331\teval-mae:0.73295\n",
      "[156]\ttrain-mae:0.68324\teval-mae:0.73296\n",
      "[157]\ttrain-mae:0.68319\teval-mae:0.73294\n",
      "[158]\ttrain-mae:0.68316\teval-mae:0.73291\n",
      "[159]\ttrain-mae:0.68308\teval-mae:0.73294\n",
      "[160]\ttrain-mae:0.68302\teval-mae:0.73297\n",
      "[161]\ttrain-mae:0.68297\teval-mae:0.73298\n",
      "[162]\ttrain-mae:0.68293\teval-mae:0.73298\n",
      "[163]\ttrain-mae:0.68288\teval-mae:0.73296\n",
      "[164]\ttrain-mae:0.68284\teval-mae:0.73294\n",
      "[165]\ttrain-mae:0.68279\teval-mae:0.73292\n",
      "[166]\ttrain-mae:0.68273\teval-mae:0.73294\n",
      "[167]\ttrain-mae:0.68268\teval-mae:0.73291\n",
      "[168]\ttrain-mae:0.68262\teval-mae:0.73286\n",
      "[169]\ttrain-mae:0.68256\teval-mae:0.73293\n",
      "[170]\ttrain-mae:0.68251\teval-mae:0.73289\n",
      "[171]\ttrain-mae:0.68241\teval-mae:0.73283\n",
      "[172]\ttrain-mae:0.68235\teval-mae:0.73279\n",
      "[173]\ttrain-mae:0.68229\teval-mae:0.73279\n",
      "[174]\ttrain-mae:0.68222\teval-mae:0.73283\n",
      "[175]\ttrain-mae:0.68220\teval-mae:0.73283\n",
      "[176]\ttrain-mae:0.68212\teval-mae:0.73282\n",
      "[177]\ttrain-mae:0.68208\teval-mae:0.73282\n",
      "[178]\ttrain-mae:0.68198\teval-mae:0.73280\n",
      "[179]\ttrain-mae:0.68189\teval-mae:0.73279\n",
      "[180]\ttrain-mae:0.68185\teval-mae:0.73280\n",
      "[181]\ttrain-mae:0.68181\teval-mae:0.73280\n",
      "[182]\ttrain-mae:0.68168\teval-mae:0.73282\n",
      "[183]\ttrain-mae:0.68153\teval-mae:0.73278\n",
      "[184]\ttrain-mae:0.68145\teval-mae:0.73279\n",
      "[185]\ttrain-mae:0.68130\teval-mae:0.73277\n",
      "[186]\ttrain-mae:0.68126\teval-mae:0.73276\n",
      "[187]\ttrain-mae:0.68122\teval-mae:0.73275\n",
      "[188]\ttrain-mae:0.68115\teval-mae:0.73278\n",
      "[189]\ttrain-mae:0.68108\teval-mae:0.73277\n",
      "[190]\ttrain-mae:0.68095\teval-mae:0.73273\n",
      "[191]\ttrain-mae:0.68089\teval-mae:0.73272\n",
      "[192]\ttrain-mae:0.68077\teval-mae:0.73257\n",
      "[193]\ttrain-mae:0.68070\teval-mae:0.73258\n",
      "[194]\ttrain-mae:0.68066\teval-mae:0.73254\n",
      "[195]\ttrain-mae:0.68061\teval-mae:0.73247\n",
      "[196]\ttrain-mae:0.68055\teval-mae:0.73244\n",
      "[197]\ttrain-mae:0.68043\teval-mae:0.73239\n",
      "[198]\ttrain-mae:0.68037\teval-mae:0.73239\n",
      "[199]\ttrain-mae:0.68023\teval-mae:0.73235\n",
      "[200]\ttrain-mae:0.68011\teval-mae:0.73236\n",
      "[201]\ttrain-mae:0.68001\teval-mae:0.73229\n",
      "[202]\ttrain-mae:0.67992\teval-mae:0.73233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203]\ttrain-mae:0.67980\teval-mae:0.73233\n",
      "[204]\ttrain-mae:0.67972\teval-mae:0.73238\n",
      "[205]\ttrain-mae:0.67969\teval-mae:0.73236\n",
      "[206]\ttrain-mae:0.67961\teval-mae:0.73239\n",
      "[207]\ttrain-mae:0.67950\teval-mae:0.73232\n",
      "[208]\ttrain-mae:0.67947\teval-mae:0.73232\n",
      "[209]\ttrain-mae:0.67938\teval-mae:0.73228\n",
      "[210]\ttrain-mae:0.67930\teval-mae:0.73227\n",
      "[211]\ttrain-mae:0.67920\teval-mae:0.73224\n",
      "[212]\ttrain-mae:0.67916\teval-mae:0.73221\n",
      "[213]\ttrain-mae:0.67914\teval-mae:0.73219\n",
      "[214]\ttrain-mae:0.67910\teval-mae:0.73219\n",
      "[215]\ttrain-mae:0.67898\teval-mae:0.73220\n",
      "[216]\ttrain-mae:0.67890\teval-mae:0.73222\n",
      "[217]\ttrain-mae:0.67881\teval-mae:0.73227\n",
      "[218]\ttrain-mae:0.67871\teval-mae:0.73220\n",
      "[219]\ttrain-mae:0.67866\teval-mae:0.73220\n",
      "[220]\ttrain-mae:0.67851\teval-mae:0.73218\n",
      "[221]\ttrain-mae:0.67843\teval-mae:0.73214\n",
      "[222]\ttrain-mae:0.67841\teval-mae:0.73212\n",
      "[223]\ttrain-mae:0.67832\teval-mae:0.73204\n",
      "[224]\ttrain-mae:0.67825\teval-mae:0.73203\n",
      "[225]\ttrain-mae:0.67820\teval-mae:0.73206\n",
      "[226]\ttrain-mae:0.67815\teval-mae:0.73210\n",
      "[227]\ttrain-mae:0.67802\teval-mae:0.73211\n",
      "[228]\ttrain-mae:0.67794\teval-mae:0.73214\n",
      "[229]\ttrain-mae:0.67786\teval-mae:0.73215\n",
      "[230]\ttrain-mae:0.67781\teval-mae:0.73213\n",
      "[231]\ttrain-mae:0.67777\teval-mae:0.73216\n",
      "[232]\ttrain-mae:0.67774\teval-mae:0.73218\n",
      "[233]\ttrain-mae:0.67769\teval-mae:0.73215\n",
      "[234]\ttrain-mae:0.67765\teval-mae:0.73217\n",
      "[235]\ttrain-mae:0.67758\teval-mae:0.73213\n",
      "[236]\ttrain-mae:0.67751\teval-mae:0.73210\n",
      "[237]\ttrain-mae:0.67747\teval-mae:0.73204\n",
      "[238]\ttrain-mae:0.67742\teval-mae:0.73203\n",
      "[239]\ttrain-mae:0.67734\teval-mae:0.73200\n",
      "[240]\ttrain-mae:0.67729\teval-mae:0.73197\n",
      "[241]\ttrain-mae:0.67718\teval-mae:0.73191\n",
      "[242]\ttrain-mae:0.67713\teval-mae:0.73190\n",
      "[243]\ttrain-mae:0.67709\teval-mae:0.73189\n",
      "[244]\ttrain-mae:0.67703\teval-mae:0.73190\n",
      "[245]\ttrain-mae:0.67697\teval-mae:0.73190\n",
      "[246]\ttrain-mae:0.67690\teval-mae:0.73188\n",
      "[247]\ttrain-mae:0.67686\teval-mae:0.73187\n",
      "[248]\ttrain-mae:0.67680\teval-mae:0.73188\n",
      "[249]\ttrain-mae:0.67671\teval-mae:0.73192\n",
      "[250]\ttrain-mae:0.67661\teval-mae:0.73197\n",
      "[251]\ttrain-mae:0.67650\teval-mae:0.73202\n",
      "[252]\ttrain-mae:0.67646\teval-mae:0.73202\n",
      "[253]\ttrain-mae:0.67639\teval-mae:0.73204\n",
      "[254]\ttrain-mae:0.67628\teval-mae:0.73199\n",
      "[255]\ttrain-mae:0.67623\teval-mae:0.73200\n",
      "[256]\ttrain-mae:0.67622\teval-mae:0.73197\n",
      "[257]\ttrain-mae:0.67612\teval-mae:0.73207\n",
      "[258]\ttrain-mae:0.67607\teval-mae:0.73207\n",
      "[259]\ttrain-mae:0.67597\teval-mae:0.73204\n",
      "[260]\ttrain-mae:0.67583\teval-mae:0.73207\n",
      "[261]\ttrain-mae:0.67570\teval-mae:0.73207\n",
      "[262]\ttrain-mae:0.67561\teval-mae:0.73212\n",
      "[263]\ttrain-mae:0.67555\teval-mae:0.73205\n",
      "[264]\ttrain-mae:0.67551\teval-mae:0.73202\n",
      "[265]\ttrain-mae:0.67539\teval-mae:0.73202\n",
      "[266]\ttrain-mae:0.67531\teval-mae:0.73204\n",
      "[267]\ttrain-mae:0.67526\teval-mae:0.73203\n",
      "[268]\ttrain-mae:0.67523\teval-mae:0.73202\n",
      "[269]\ttrain-mae:0.67520\teval-mae:0.73202\n",
      "[270]\ttrain-mae:0.67518\teval-mae:0.73200\n",
      "[271]\ttrain-mae:0.67510\teval-mae:0.73198\n",
      "[272]\ttrain-mae:0.67507\teval-mae:0.73201\n",
      "[273]\ttrain-mae:0.67502\teval-mae:0.73204\n",
      "[274]\ttrain-mae:0.67496\teval-mae:0.73201\n",
      "[275]\ttrain-mae:0.67492\teval-mae:0.73202\n",
      "[276]\ttrain-mae:0.67486\teval-mae:0.73198\n",
      "[277]\ttrain-mae:0.67483\teval-mae:0.73198\n",
      "[278]\ttrain-mae:0.67476\teval-mae:0.73189\n",
      "[279]\ttrain-mae:0.67469\teval-mae:0.73186\n",
      "[280]\ttrain-mae:0.67463\teval-mae:0.73179\n",
      "[281]\ttrain-mae:0.67453\teval-mae:0.73178\n",
      "[282]\ttrain-mae:0.67449\teval-mae:0.73177\n",
      "[283]\ttrain-mae:0.67446\teval-mae:0.73178\n",
      "[284]\ttrain-mae:0.67444\teval-mae:0.73174\n",
      "[285]\ttrain-mae:0.67438\teval-mae:0.73167\n",
      "[286]\ttrain-mae:0.67436\teval-mae:0.73167\n",
      "[287]\ttrain-mae:0.67433\teval-mae:0.73166\n",
      "[288]\ttrain-mae:0.67430\teval-mae:0.73164\n",
      "[289]\ttrain-mae:0.67424\teval-mae:0.73162\n",
      "[290]\ttrain-mae:0.67421\teval-mae:0.73160\n",
      "[291]\ttrain-mae:0.67415\teval-mae:0.73159\n",
      "[292]\ttrain-mae:0.67413\teval-mae:0.73159\n",
      "[293]\ttrain-mae:0.67409\teval-mae:0.73153\n",
      "[294]\ttrain-mae:0.67406\teval-mae:0.73159\n",
      "[295]\ttrain-mae:0.67401\teval-mae:0.73159\n",
      "[296]\ttrain-mae:0.67395\teval-mae:0.73161\n",
      "[297]\ttrain-mae:0.67394\teval-mae:0.73160\n",
      "[298]\ttrain-mae:0.67386\teval-mae:0.73164\n",
      "[299]\ttrain-mae:0.67382\teval-mae:0.73166\n",
      "[300]\ttrain-mae:0.67377\teval-mae:0.73167\n",
      "[301]\ttrain-mae:0.67371\teval-mae:0.73162\n",
      "[302]\ttrain-mae:0.67361\teval-mae:0.73162\n",
      "[303]\ttrain-mae:0.67352\teval-mae:0.73156\n",
      "[304]\ttrain-mae:0.67348\teval-mae:0.73155\n",
      "[305]\ttrain-mae:0.67343\teval-mae:0.73153\n",
      "[306]\ttrain-mae:0.67340\teval-mae:0.73153\n",
      "[307]\ttrain-mae:0.67338\teval-mae:0.73149\n",
      "[308]\ttrain-mae:0.67333\teval-mae:0.73146\n",
      "[309]\ttrain-mae:0.67331\teval-mae:0.73145\n",
      "[310]\ttrain-mae:0.67325\teval-mae:0.73145\n",
      "[311]\ttrain-mae:0.67322\teval-mae:0.73144\n",
      "[312]\ttrain-mae:0.67320\teval-mae:0.73143\n",
      "[313]\ttrain-mae:0.67318\teval-mae:0.73142\n",
      "[314]\ttrain-mae:0.67313\teval-mae:0.73142\n",
      "[315]\ttrain-mae:0.67311\teval-mae:0.73141\n",
      "[316]\ttrain-mae:0.67308\teval-mae:0.73140\n",
      "[317]\ttrain-mae:0.67303\teval-mae:0.73137\n",
      "[318]\ttrain-mae:0.67299\teval-mae:0.73143\n",
      "[319]\ttrain-mae:0.67295\teval-mae:0.73142\n",
      "[320]\ttrain-mae:0.67292\teval-mae:0.73144\n",
      "[321]\ttrain-mae:0.67287\teval-mae:0.73146\n",
      "[322]\ttrain-mae:0.67283\teval-mae:0.73145\n",
      "[323]\ttrain-mae:0.67278\teval-mae:0.73145\n",
      "[324]\ttrain-mae:0.67272\teval-mae:0.73154\n",
      "[325]\ttrain-mae:0.67267\teval-mae:0.73155\n",
      "[326]\ttrain-mae:0.67265\teval-mae:0.73153\n",
      "[327]\ttrain-mae:0.67261\teval-mae:0.73153\n",
      "[328]\ttrain-mae:0.67259\teval-mae:0.73153\n",
      "[329]\ttrain-mae:0.67251\teval-mae:0.73154\n",
      "[330]\ttrain-mae:0.67242\teval-mae:0.73147\n",
      "[331]\ttrain-mae:0.67238\teval-mae:0.73147\n",
      "[332]\ttrain-mae:0.67232\teval-mae:0.73144\n",
      "[333]\ttrain-mae:0.67221\teval-mae:0.73146\n",
      "[334]\ttrain-mae:0.67212\teval-mae:0.73145\n",
      "[335]\ttrain-mae:0.67204\teval-mae:0.73147\n",
      "[336]\ttrain-mae:0.67198\teval-mae:0.73148\n",
      "[337]\ttrain-mae:0.67195\teval-mae:0.73146\n",
      "[338]\ttrain-mae:0.67190\teval-mae:0.73148\n",
      "[339]\ttrain-mae:0.67185\teval-mae:0.73149\n",
      "[340]\ttrain-mae:0.67182\teval-mae:0.73150\n",
      "[341]\ttrain-mae:0.67177\teval-mae:0.73150\n",
      "[342]\ttrain-mae:0.67174\teval-mae:0.73152\n",
      "[343]\ttrain-mae:0.67166\teval-mae:0.73155\n",
      "[344]\ttrain-mae:0.67163\teval-mae:0.73153\n",
      "[345]\ttrain-mae:0.67153\teval-mae:0.73150\n",
      "[346]\ttrain-mae:0.67150\teval-mae:0.73149\n",
      "[347]\ttrain-mae:0.67143\teval-mae:0.73150\n",
      "[348]\ttrain-mae:0.67138\teval-mae:0.73150\n",
      "[349]\ttrain-mae:0.67137\teval-mae:0.73149\n",
      "[350]\ttrain-mae:0.67130\teval-mae:0.73155\n",
      "[351]\ttrain-mae:0.67127\teval-mae:0.73157\n",
      "[352]\ttrain-mae:0.67116\teval-mae:0.73156\n",
      "[353]\ttrain-mae:0.67109\teval-mae:0.73156\n",
      "[354]\ttrain-mae:0.67106\teval-mae:0.73156\n",
      "[355]\ttrain-mae:0.67101\teval-mae:0.73154\n",
      "[356]\ttrain-mae:0.67097\teval-mae:0.73155\n",
      "[357]\ttrain-mae:0.67092\teval-mae:0.73159\n",
      "[358]\ttrain-mae:0.67088\teval-mae:0.73159\n",
      "[359]\ttrain-mae:0.67082\teval-mae:0.73164\n",
      "[360]\ttrain-mae:0.67077\teval-mae:0.73165\n",
      "[361]\ttrain-mae:0.67074\teval-mae:0.73166\n",
      "[362]\ttrain-mae:0.67069\teval-mae:0.73163\n",
      "[363]\ttrain-mae:0.67063\teval-mae:0.73158\n",
      "[364]\ttrain-mae:0.67059\teval-mae:0.73159\n",
      "[365]\ttrain-mae:0.67057\teval-mae:0.73161\n",
      "[366]\ttrain-mae:0.67054\teval-mae:0.73160\n",
      "[367]\ttrain-mae:0.67053\teval-mae:0.73158\n",
      "Test MAE: 0.7243\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "user_id_train, item_id_train, y_train = train_tuple\n",
    "user_id_valid, item_id_valid, y_valid = valid_tuple\n",
    "user_id_test, item_id_test, y_test = test_tuple\n",
    "\n",
    "train_df = pd.DataFrame({'user_id': user_id_train, 'item_id': item_id_train, 'rating': y_train})\n",
    "valid_df = pd.DataFrame({'user_id': user_id_valid, 'item_id': item_id_valid, 'rating': y_valid})\n",
    "test_df = pd.DataFrame({'user_id': user_id_test, 'item_id': item_id_test})\n",
    "\n",
    "user_means = train_df.groupby('user_id')['rating'].mean().rename(\"user_mean_rating\")\n",
    "item_means = train_df.groupby('item_id')['rating'].mean().rename(\"item_mean_rating\")\n",
    "\n",
    "train_df = train_df.merge(user_means, on='user_id').merge(item_means, on='item_id')\n",
    "valid_df = valid_df.merge(user_means, on='user_id', how='left').merge(item_means, on='item_id', how='left')\n",
    "test_df = test_df.merge(user_means, on='user_id', how='left').merge(item_means, on='item_id', how='left')\n",
    "\n",
    "valid_df.fillna({'user_mean_rating': train_df['rating'].mean(),\n",
    "                 'item_mean_rating': train_df['rating'].mean()}, inplace=True)\n",
    "test_df.fillna({'user_mean_rating': train_df['rating'].mean(),\n",
    "                'item_mean_rating': train_df['rating'].mean()}, inplace=True)\n",
    "\n",
    "X_train = train_df.drop(columns=[\"rating\"])\n",
    "y_train = train_df[\"rating\"]\n",
    "X_valid = valid_df.drop(columns=[\"rating\"])\n",
    "y_valid = valid_df[\"rating\"]\n",
    "X_test = test_df \n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# tuned hyperparameters\n",
    "params = {\n",
    "    \"objective\": \"reg:absoluteerror\",\n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.1,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8\n",
    "}\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dvalid, \"eval\")]\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=1000, evals=evals, early_stopping_rounds=50)\n",
    "\n",
    "y_pred_test = xgb_model.predict(dtest)\n",
    "\n",
    "test_df[\"rating\"] = y_test \n",
    "test_mae = mean_absolute_error(test_df[\"rating\"], y_pred_test)\n",
    "print(f\"Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6771c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "leaderboard_df = pd.read_csv(\"data_movie_lens_100k/ratings_masked_leaderboard_set.csv\")\n",
    "\n",
    "leaderboard_df = leaderboard_df.merge(user_means, on=\"user_id\", how=\"left\")\n",
    "leaderboard_df = leaderboard_df.merge(item_means, on=\"item_id\", how=\"left\")\n",
    "\n",
    "leaderboard_df.fillna({\n",
    "    \"user_mean_rating\": train_df[\"rating\"].mean(),\n",
    "    \"item_mean_rating\": train_df[\"rating\"].mean()\n",
    "}, inplace=True)\n",
    "\n",
    "X_leaderboard = leaderboard_df.drop(columns=[\"rating\"])\n",
    "\n",
    "dleaderboard = xgb.DMatrix(X_leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cefb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_leaderboard = xgb_model.predict(dleaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19d4ad5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predicted_ratings_leaderboard.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"predicted_ratings_leaderboard.txt\", \"w\") as f:\n",
    "    for pred in y_pred_leaderboard:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "\n",
    "print(\"Predictions saved to predicted_ratings_leaderboard.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d70073a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded predictions shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "predictions = np.loadtxt(\"predicted_ratings_leaderboard.txt\")\n",
    "print(f\"Loaded predictions shape: {predictions.shape}\")  # Should print (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b39962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
