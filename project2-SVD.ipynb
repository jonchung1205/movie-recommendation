{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Model - This should get MAE of around 0.52 ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as ag_np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# %pip install autograd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "DATA_DIR = './data_movie_lens_100k'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = load_train_valid_test_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import os\n",
    "from surprise import SVD, Reader, Dataset\n",
    "from surprise.model_selection import GridSearchCV, train_test_split\n",
    "from surprise import accuracy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Specify the folder containing the data\n",
    "data_folder = 'data_movie_lens_100k'\n",
    "\n",
    "# Load the additional data (user and movie info) from the specified folder\n",
    "user_info = pd.read_csv(os.path.join(data_folder, 'user_info.csv'))\n",
    "movie_info = pd.read_csv(os.path.join(data_folder, 'movie_info.csv'))\n",
    "\n",
    "# Example of encoding additional features for users and items\n",
    "# One-hot encode user info (age and gender)\n",
    "user_info['age_group'] = pd.cut(user_info['age'], bins=[0, 18, 30, 40, 50, 100], labels=[\"0-18\", \"19-30\", \"31-40\", \"41-50\", \"50+\"])\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_user_info = encoder.fit_transform(user_info[['age_group', 'is_male']])\n",
    "\n",
    "# One-hot encode movie info (release year)\n",
    "movie_info['release_year'] = movie_info['release_year'].astype(str)\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_movie_info = encoder.fit_transform(movie_info[['release_year']])\n",
    "\n",
    "# Merge the encoded user and movie info with the original datasets\n",
    "user_info_encoded = pd.DataFrame(encoded_user_info, columns=encoder.get_feature_names_out())\n",
    "movie_info_encoded = pd.DataFrame(encoded_movie_info, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Merge with original ratings data\n",
    "train_data = pd.read_csv(os.path.join(data_folder, \"ratings_all_development_set.csv\"))\n",
    "train_data = pd.merge(train_data, user_info, on=\"user_id\", how=\"left\")\n",
    "train_data = pd.merge(train_data, movie_info, on=\"item_id\", how=\"left\")\n",
    "\n",
    "# Convert to Surprise format\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_dataset = Dataset.load_from_df(train_data[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Train-test split for validation and testing\n",
    "trainset, testset = train_test_split(train_dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_factors': [50, 100, 150],\n",
    "    'reg_all': [0.1, 0.2, 0.3],\n",
    "    'lr_all': [0.002, 0.005],\n",
    "    'n_epochs': [20, 30]\n",
    "}\n",
    "\n",
    "# Perform GridSearch for best SVD model\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "grid_search.fit(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_svd = grid_search.best_estimator['mae']\n",
    "\n",
    "# Train the best model on the entire training data\n",
    "trainset = train_dataset.build_full_trainset()\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "# Test on the test set\n",
    "test_dataset = Dataset.load_from_df(train_data[['user_id', 'item_id', 'rating']], reader)  # Reuse train_data as example\n",
    "testset = test_dataset.build_full_trainset().build_testset()\n",
    "predictions = best_svd.test(testset)\n",
    "\n",
    "# Evaluate MAE\n",
    "mae = accuracy.mae(predictions)\n",
    "print(f\"Test MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract hyperparameter results from the grid search\n",
    "results = grid_search.cv_results\n",
    "param_factors = results['param_n_factors']\n",
    "mean_mae = results['mean_test_mae']\n",
    "std_mae = results['std_test_mae']\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.errorbar(param_factors, mean_mae, yerr=std_mae, fmt='o-', capsize=5, label='Mean MAE Â± StdDev', color='blue')\n",
    "plt.xlabel('Number of Latent Factors (n_factors)', fontsize=12)\n",
    "plt.ylabel('Mean Absolute Error (MAE)', fontsize=12)\n",
    "plt.title('Hyperparameter Selection for SVD: Impact of n_factors', fontsize=14)\n",
    "plt.xticks(param_factors, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save or display the plot\n",
    "plt.savefig('hyperparameter_selection_plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training the SVD model and recording error over epochs\n",
    "n_epochs = 50  # Example: Training with 50 epochs\n",
    "svd = SVD(n_factors=100, reg_all=0.1, lr_all=0.002, n_epochs=n_epochs)\n",
    "\n",
    "# Track training error\n",
    "train_errors = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    svd.epochs = epoch\n",
    "    svd.fit(trainset)\n",
    "    predictions = svd.test(trainset.build_testset())\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "    train_errors.append(mae)\n",
    "\n",
    "# Plotting the trace plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, n_epochs + 1), train_errors, marker='o', color='blue', label='Training MAE')\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Mean Absolute Error (MAE)', fontsize=12)\n",
    "plt.title('Training Trace Plot for SVD', fontsize=14)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save or display the plot\n",
    "plt.savefig('trace_plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
