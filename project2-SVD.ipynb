{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Model ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as ag_np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# %pip install autograd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from CollabFilterOneVectorPerItem import CollabFilterOneVectorPerItem\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "DATA_DIR = './data_movie_lens_100k'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = load_train_valid_test_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the folder containing the data\n",
    "data_folder = 'data_movie_lens_100k'\n",
    "\n",
    "# Load the additional data (user and movie info) from the specified folder\n",
    "user_info = pd.read_csv(os.path.join(data_folder, 'user_info.csv'))\n",
    "movie_info = pd.read_csv(os.path.join(data_folder, 'movie_info.csv'))\n",
    "\n",
    "# Example of encoding additional features for users and items\n",
    "# One-hot encode user info (age and gender)\n",
    "user_info['age_group'] = pd.cut(user_info['age'], bins=[0, 18, 30, 40, 50, 100], labels=[\"0-18\", \"19-30\", \"31-40\", \"41-50\", \"50+\"])\n",
    "\n",
    "# Use the correct argument for sparse matrix\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Encode the 'age_group' and 'is_male' columns separately\n",
    "encoded_user_info = encoder.fit_transform(user_info[['age_group', 'is_male']])\n",
    "\n",
    "# One-hot encode movie info (release year)\n",
    "movie_info['release_year'] = movie_info['release_year'].astype(str)\n",
    "encoder_movie = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Encode the 'release_year' column\n",
    "encoded_movie_info = encoder_movie.fit_transform(movie_info[['release_year']])\n",
    "\n",
    "# Now, assign the feature names correctly by using encoder.get_feature_names_out()\n",
    "user_info_encoded = pd.DataFrame(encoded_user_info, columns=encoder.get_feature_names_out(['age_group', 'is_male']))\n",
    "movie_info_encoded = pd.DataFrame(encoded_movie_info, columns=encoder_movie.get_feature_names_out(['release_year']))\n",
    "\n",
    "# Merge with the original datasets\n",
    "user_info = pd.concat([user_info, user_info_encoded], axis=1)\n",
    "movie_info = pd.concat([movie_info, movie_info_encoded], axis=1)\n",
    "\n",
    "# Merge user and movie info with the ratings data\n",
    "train_data = pd.read_csv(os.path.join(data_folder, \"ratings_all_development_set.csv\"))\n",
    "train_data = pd.merge(train_data, user_info, on=\"user_id\", how=\"left\")\n",
    "train_data = pd.merge(train_data, movie_info, on=\"item_id\", how=\"left\")\n",
    "\n",
    "# Convert to Surprise format\n",
    "from surprise import Reader, Dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_dataset = Dataset.load_from_df(train_data[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Train-test split for validation and testing\n",
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(train_dataset, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract hyperparameter results from the grid search\n",
    "results = grid_search.cv_results\n",
    "param_factors = results['param_n_factors']\n",
    "mean_mae = results['mean_test_mae']\n",
    "std_mae = results['std_test_mae']\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.errorbar(param_factors, mean_mae, yerr=std_mae, fmt='o-', capsize=5, label='Mean MAE Â± StdDev', color='blue')\n",
    "plt.xlabel('Number of Latent Factors (n_factors)', fontsize=12)\n",
    "plt.ylabel('Mean Absolute Error (MAE)', fontsize=12)\n",
    "plt.title('Hyperparameter Selection for SVD: Impact of n_factors', fontsize=14)\n",
    "plt.xticks(param_factors, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save or display the plot\n",
    "plt.savefig('hyperparameter_selection_plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training the SVD model and recording error over epochs\n",
    "n_epochs = 50  # Example: Training with 50 epochs\n",
    "svd = SVD(n_factors=100, reg_all=0.1, lr_all=0.002, n_epochs=n_epochs)\n",
    "\n",
    "# Track training error\n",
    "train_errors = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    svd.epochs = epoch\n",
    "    svd.fit(trainset)\n",
    "    predictions = svd.test(trainset.build_testset())\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "    train_errors.append(mae)\n",
    "\n",
    "# Plotting the trace plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, n_epochs + 1), train_errors, marker='o', color='blue', label='Training MAE')\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Mean Absolute Error (MAE)', fontsize=12)\n",
    "plt.title('Training Trace Plot for SVD', fontsize=14)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save or display the plot\n",
    "plt.savefig('trace_plot.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
